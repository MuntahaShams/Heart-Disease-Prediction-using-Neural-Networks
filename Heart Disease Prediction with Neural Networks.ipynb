{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction using Neural Networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing the Dataset\n",
    "\n",
    "The dataset is available through the University of California, Irvine Machine learning repository. Here is the URL:\n",
    "\n",
    "http:////archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "This dataset contains patient data concerning heart disease diagnosis that was collected at several locations around the world. There are 76 attributes, including age, sex, resting blood pressure, cholestoral levels, echocardiogram data, exercise habits, and many others. To data, all published studies using this data focus on a subset of 14 attributes - so we will do the same. More specifically, we will use the data collected at the Cleveland Clinic Foundation.\n",
    "\n",
    "To import the necessary data, we will use pandas' built in read_csv() function. Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the heart disease dataset\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "\n",
    "# the names will be the names of each column in our pandas DataFrame\n",
    "names = ['age',\n",
    "        'sex',\n",
    "        'cp',\n",
    "        'trestbps',\n",
    "        'chol',\n",
    "        'fbs',\n",
    "        'restecg',\n",
    "        'thalach',\n",
    "        'exang',\n",
    "        'oldpeak',\n",
    "        'slope',\n",
    "        'ca',\n",
    "        'thal',\n",
    "        'class']\n",
    "\n",
    "# read the csv\n",
    "cleveland = pd.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format(cleveland.shape\n",
      "age          67\n",
      "sex           1\n",
      "cp            4\n",
      "trestbps    160\n",
      "chol        286\n",
      "fbs           0\n",
      "restecg       2\n",
      "thalach     108\n",
      "exang         1\n",
      "oldpeak     1.5\n",
      "slope         2\n",
      "ca          3.0\n",
      "thal        3.0\n",
      "class         2\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the DataFrame, so we can see how many examples we have\n",
    "print ('format(cleveland.shape')\n",
    "print (cleveland.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "280  57.0  1.0  4.0     110.0  335.0  0.0      0.0    143.0    1.0      3.0   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0      0.0    179.0    0.0      0.0   \n",
       "282  55.0  0.0  4.0     128.0  205.0  0.0      1.0    130.0    1.0      2.0   \n",
       "283  35.0  1.0  2.0     122.0  192.0  0.0      0.0    174.0    0.0      0.0   \n",
       "284  61.0  1.0  4.0     148.0  203.0  0.0      0.0    161.0    0.0      0.0   \n",
       "285  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "286  58.0  0.0  4.0     170.0  225.0  1.0      2.0    146.0    1.0      2.8   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "288  56.0  1.0  2.0     130.0  221.0  0.0      2.0    163.0    0.0      0.0   \n",
       "289  56.0  1.0  2.0     120.0  240.0  0.0      0.0    169.0    0.0      0.0   \n",
       "290  67.0  1.0  3.0     152.0  212.0  0.0      2.0    150.0    0.0      0.8   \n",
       "291  55.0  0.0  2.0     132.0  342.0  0.0      0.0    166.0    0.0      1.2   \n",
       "292  44.0  1.0  4.0     120.0  169.0  0.0      0.0    144.0    1.0      2.8   \n",
       "293  63.0  1.0  4.0     140.0  187.0  0.0      2.0    144.0    1.0      4.0   \n",
       "294  63.0  0.0  4.0     124.0  197.0  0.0      0.0    136.0    1.0      0.0   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0      0.0    182.0    0.0      0.0   \n",
       "296  59.0  1.0  4.0     164.0  176.0  1.0      2.0     90.0    0.0      1.0   \n",
       "297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "280    2.0  1.0  7.0      2  \n",
       "281    1.0  0.0  3.0      0  \n",
       "282    2.0  1.0  7.0      3  \n",
       "283    1.0  0.0  3.0      0  \n",
       "284    1.0  1.0  7.0      2  \n",
       "285    3.0  3.0  6.0      4  \n",
       "286    2.0  2.0  6.0      2  \n",
       "287    2.0    ?  7.0      0  \n",
       "288    1.0  0.0  7.0      0  \n",
       "289    3.0  0.0  3.0      0  \n",
       "290    2.0  0.0  7.0      1  \n",
       "291    1.0  0.0  3.0      0  \n",
       "292    3.0  0.0  6.0      2  \n",
       "293    1.0  2.0  7.0      2  \n",
       "294    2.0  0.0  3.0      1  \n",
       "295    1.0  0.0  3.0      0  \n",
       "296    2.0  2.0  6.0      3  \n",
       "297    2.0  0.0  7.0      1  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  \n",
       "302    1.0    ?  3.0      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the last twenty or so data points\n",
    "cleveland.loc[280:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>302</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "280  57.0  1.0  4.0     110.0  335.0  0.0      0.0    143.0    1.0      3.0   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0      0.0    179.0    0.0      0.0   \n",
       "282  55.0  0.0  4.0     128.0  205.0  0.0      1.0    130.0    1.0      2.0   \n",
       "283  35.0  1.0  2.0     122.0  192.0  0.0      0.0    174.0    0.0      0.0   \n",
       "284  61.0  1.0  4.0     148.0  203.0  0.0      0.0    161.0    0.0      0.0   \n",
       "285  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "286  58.0  0.0  4.0     170.0  225.0  1.0      2.0    146.0    1.0      2.8   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "288  56.0  1.0  2.0     130.0  221.0  0.0      2.0    163.0    0.0      0.0   \n",
       "289  56.0  1.0  2.0     120.0  240.0  0.0      0.0    169.0    0.0      0.0   \n",
       "290  67.0  1.0  3.0     152.0  212.0  0.0      2.0    150.0    0.0      0.8   \n",
       "291  55.0  0.0  2.0     132.0  342.0  0.0      0.0    166.0    0.0      1.2   \n",
       "292  44.0  1.0  4.0     120.0  169.0  0.0      0.0    144.0    1.0      2.8   \n",
       "293  63.0  1.0  4.0     140.0  187.0  0.0      2.0    144.0    1.0      4.0   \n",
       "294  63.0  0.0  4.0     124.0  197.0  0.0      0.0    136.0    1.0      0.0   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0      0.0    182.0    0.0      0.0   \n",
       "296  59.0  1.0  4.0     164.0  176.0  1.0      2.0     90.0    0.0      1.0   \n",
       "297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "280    2.0  1.0  7.0      2  \n",
       "281    1.0  0.0  3.0      0  \n",
       "282    2.0  1.0  7.0      3  \n",
       "283    1.0  0.0  3.0      0  \n",
       "284    1.0  1.0  7.0      2  \n",
       "285    3.0  3.0  6.0      4  \n",
       "286    2.0  2.0  6.0      2  \n",
       "287    2.0  NaN  7.0      0  \n",
       "288    1.0  0.0  7.0      0  \n",
       "289    3.0  0.0  3.0      0  \n",
       "290    2.0  0.0  7.0      1  \n",
       "291    1.0  0.0  3.0      0  \n",
       "292    3.0  0.0  6.0      2  \n",
       "293    1.0  2.0  7.0      2  \n",
       "294    2.0  0.0  3.0      1  \n",
       "295    1.0  0.0  3.0      0  \n",
       "296    2.0  2.0  6.0      3  \n",
       "297    2.0  0.0  7.0      1  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  \n",
       "302    1.0  NaN  3.0      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing data (indicated with a \"?\")\n",
    "data = cleveland[~cleveland.isin(['?'])]\n",
    "data.loc[280:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>282</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>284</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>286</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>289</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "280  57.0  1.0  4.0     110.0  335.0  0.0      0.0    143.0    1.0      3.0   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0      0.0    179.0    0.0      0.0   \n",
       "282  55.0  0.0  4.0     128.0  205.0  0.0      1.0    130.0    1.0      2.0   \n",
       "283  35.0  1.0  2.0     122.0  192.0  0.0      0.0    174.0    0.0      0.0   \n",
       "284  61.0  1.0  4.0     148.0  203.0  0.0      0.0    161.0    0.0      0.0   \n",
       "285  58.0  1.0  4.0     114.0  318.0  0.0      1.0    140.0    0.0      4.4   \n",
       "286  58.0  0.0  4.0     170.0  225.0  1.0      2.0    146.0    1.0      2.8   \n",
       "288  56.0  1.0  2.0     130.0  221.0  0.0      2.0    163.0    0.0      0.0   \n",
       "289  56.0  1.0  2.0     120.0  240.0  0.0      0.0    169.0    0.0      0.0   \n",
       "290  67.0  1.0  3.0     152.0  212.0  0.0      2.0    150.0    0.0      0.8   \n",
       "291  55.0  0.0  2.0     132.0  342.0  0.0      0.0    166.0    0.0      1.2   \n",
       "292  44.0  1.0  4.0     120.0  169.0  0.0      0.0    144.0    1.0      2.8   \n",
       "293  63.0  1.0  4.0     140.0  187.0  0.0      2.0    144.0    1.0      4.0   \n",
       "294  63.0  0.0  4.0     124.0  197.0  0.0      0.0    136.0    1.0      0.0   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0      0.0    182.0    0.0      0.0   \n",
       "296  59.0  1.0  4.0     164.0  176.0  1.0      2.0     90.0    0.0      1.0   \n",
       "297  57.0  0.0  4.0     140.0  241.0  0.0      0.0    123.0    1.0      0.2   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  class  \n",
       "280    2.0  1.0  7.0      2  \n",
       "281    1.0  0.0  3.0      0  \n",
       "282    2.0  1.0  7.0      3  \n",
       "283    1.0  0.0  3.0      0  \n",
       "284    1.0  1.0  7.0      2  \n",
       "285    3.0  3.0  6.0      4  \n",
       "286    2.0  2.0  6.0      2  \n",
       "288    1.0  0.0  7.0      0  \n",
       "289    3.0  0.0  3.0      0  \n",
       "290    2.0  0.0  7.0      1  \n",
       "291    1.0  0.0  3.0      0  \n",
       "292    3.0  0.0  6.0      2  \n",
       "293    1.0  2.0  7.0      2  \n",
       "294    2.0  0.0  3.0      1  \n",
       "295    1.0  0.0  3.0      0  \n",
       "296    2.0  2.0  6.0      3  \n",
       "297    2.0  0.0  7.0      1  \n",
       "298    2.0  0.0  7.0      1  \n",
       "299    2.0  2.0  7.0      2  \n",
       "300    2.0  1.0  7.0      3  \n",
       "301    2.0  1.0  3.0      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with NaN values from DataFrame\n",
    "data = data.dropna(axis=0)\n",
    "data.loc[280:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 14)\n",
      "age         float64\n",
      "sex         float64\n",
      "cp          float64\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs         float64\n",
      "restecg     float64\n",
      "thalach     float64\n",
      "exang       float64\n",
      "oldpeak     float64\n",
      "slope       float64\n",
      "ca           object\n",
      "thal         object\n",
      "class         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print the shape and data type of the dataframe\n",
    "print (data.shape)\n",
    "print (data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         float64\n",
       "sex         float64\n",
       "cp          float64\n",
       "trestbps    float64\n",
       "chol        float64\n",
       "fbs         float64\n",
       "restecg     float64\n",
       "thalach     float64\n",
       "exang       float64\n",
       "oldpeak     float64\n",
       "slope       float64\n",
       "ca          float64\n",
       "thal        float64\n",
       "class         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform data to numeric to enable further analysis\n",
    "data = data.apply(pd.to_numeric)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>297.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>54.542088</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>3.158249</td>\n",
       "      <td>131.693603</td>\n",
       "      <td>247.350168</td>\n",
       "      <td>0.144781</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>149.599327</td>\n",
       "      <td>0.326599</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>1.602694</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>4.730640</td>\n",
       "      <td>0.946128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.049736</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.964859</td>\n",
       "      <td>17.762806</td>\n",
       "      <td>51.997583</td>\n",
       "      <td>0.352474</td>\n",
       "      <td>0.994914</td>\n",
       "      <td>22.941562</td>\n",
       "      <td>0.469761</td>\n",
       "      <td>1.166123</td>\n",
       "      <td>0.618187</td>\n",
       "      <td>0.938965</td>\n",
       "      <td>1.938629</td>\n",
       "      <td>1.234551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean    54.542088    0.676768    3.158249  131.693603  247.350168    0.144781   \n",
       "std      9.049736    0.468500    0.964859   17.762806   51.997583    0.352474   \n",
       "min     29.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     48.000000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     56.000000    1.000000    3.000000  130.000000  243.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  276.000000    0.000000   \n",
       "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  297.000000  297.000000  297.000000  297.000000  297.000000  297.000000   \n",
       "mean     0.996633  149.599327    0.326599    1.055556    1.602694    0.676768   \n",
       "std      0.994914   22.941562    0.469761    1.166123    0.618187    0.938965   \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "25%      0.000000  133.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000   \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
       "\n",
       "             thal       class  \n",
       "count  297.000000  297.000000  \n",
       "mean     4.730640    0.946128  \n",
       "std      1.938629    1.234551  \n",
       "min      3.000000    0.000000  \n",
       "25%      3.000000    0.000000  \n",
       "50%      3.000000    0.000000  \n",
       "75%      7.000000    2.000000  \n",
       "max      7.000000    4.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print data characteristics, usings pandas built-in describe() function\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histograms for each variable\n",
    "data.hist(figsize = (12, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Training and Testing Datasets\n",
    "\n",
    "Now that we have preprocessed the data appropriately, we can split it into training and testings datasets. We will use Sklearn's train_test_split() function to generate a training dataset (80 percent of the total data) and testing dataset (20 percent of the total data). \n",
    "\n",
    "Furthermore, the class values in this dataset contain multiple types of heart disease with values ranging from 0 (healthy) to 4 (severe heart disease). Consequently, we will need to convert our class data to categorical labels. For example, the label 2 will become [0, 0, 1, 0, 0]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y datasets for training\n",
    "from sklearn import model_selection\n",
    "\n",
    "X = np.array(data.drop(['class'], 1))\n",
    "y = np.array(data['class'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 5)\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# convert the data to categorical labels\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(y_train, num_classes=None)\n",
    "Y_test = to_categorical(y_test, num_classes=None)\n",
    "print (Y_train.shape)\n",
    "print (Y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building and Training the Neural Network\n",
    "\n",
    "Now that we have our data fully processed and split into training and testing datasets, we can begin building a neural network to solve this classification problem. Using keras, we will define a simple neural network with one hidden layer. Since this is a categorical classification problem, we will use a softmax activation function in the final layer of our network and a categorical_crossentropy loss during our training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 25        \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# define a function to build the keras model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    # compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 1.4000 - accuracy: 0.5232\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 0s 405us/step - loss: 1.3282 - accuracy: 0.5232\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.3082 - accuracy: 0.5232\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.2900 - accuracy: 0.5232\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.2700 - accuracy: 0.5232\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.2721 - accuracy: 0.5232\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.2489 - accuracy: 0.5232\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.2339 - accuracy: 0.5274\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.2489 - accuracy: 0.5359\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.2240 - accuracy: 0.5190\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.1979 - accuracy: 0.5359\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1957 - accuracy: 0.5274\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1792 - accuracy: 0.5359\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1837 - accuracy: 0.5232\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.1838 - accuracy: 0.5359\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1715 - accuracy: 0.5359\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1561 - accuracy: 0.5401\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 1.1466 - accuracy: 0.5443\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.1423 - accuracy: 0.5401\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1349 - accuracy: 0.5443\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.1336 - accuracy: 0.5316\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1206 - accuracy: 0.5401\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1170 - accuracy: 0.5316\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1210 - accuracy: 0.5359\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.1030 - accuracy: 0.5401\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.1014 - accuracy: 0.5401\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 1.0900 - accuracy: 0.5401\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 0s 321us/step - loss: 1.0963 - accuracy: 0.5316\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 1.0860 - accuracy: 0.5401\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.0939 - accuracy: 0.5316\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.0751 - accuracy: 0.5359\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 0s 135us/step - loss: 1.0669 - accuracy: 0.5316\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.0679 - accuracy: 0.5443\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 1.0601 - accuracy: 0.5485\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.0569 - accuracy: 0.5485\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 0s 135us/step - loss: 1.0571 - accuracy: 0.5485\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.0550 - accuracy: 0.5443\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 1.0432 - accuracy: 0.5485\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.0330 - accuracy: 0.5485\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 0s 135us/step - loss: 1.0310 - accuracy: 0.5443\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.0538 - accuracy: 0.5443\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.0338 - accuracy: 0.5485\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 1.0212 - accuracy: 0.5485\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 0s 135us/step - loss: 1.0265 - accuracy: 0.5359\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 1.0155 - accuracy: 0.5485\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 0s 135us/step - loss: 1.0116 - accuracy: 0.5527\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 0s 135us/step - loss: 1.0118 - accuracy: 0.5443\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 1.0191 - accuracy: 0.5527\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9996 - accuracy: 0.5443\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 0.9967 - accuracy: 0.5485\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9950 - accuracy: 0.5401\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 1.0106 - accuracy: 0.5612\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9987 - accuracy: 0.5527\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.9940 - accuracy: 0.5570\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9855 - accuracy: 0.5527\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9886 - accuracy: 0.5570\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9833 - accuracy: 0.5612\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9904 - accuracy: 0.5570\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9899 - accuracy: 0.5696\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9757 - accuracy: 0.5612\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9732 - accuracy: 0.5612\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9751 - accuracy: 0.5527\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 1.0040 - accuracy: 0.5570\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9621 - accuracy: 0.5654\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9667 - accuracy: 0.5696\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9681 - accuracy: 0.5654\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.9604 - accuracy: 0.5527\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9561 - accuracy: 0.5612\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9502 - accuracy: 0.5570\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9629 - accuracy: 0.5654\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9528 - accuracy: 0.5570\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9489 - accuracy: 0.5654\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9746 - accuracy: 0.6034\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9567 - accuracy: 0.6076\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 0s 304us/step - loss: 0.9429 - accuracy: 0.6034\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 0s 287us/step - loss: 0.9469 - accuracy: 0.6118\n",
      "Epoch 77/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9622 - accuracy: 0.6034\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9518 - accuracy: 0.6160\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 0s 253us/step - loss: 0.9448 - accuracy: 0.6118\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9373 - accuracy: 0.5992\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9364 - accuracy: 0.6160\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9321 - accuracy: 0.6203\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9633 - accuracy: 0.5992\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9680 - accuracy: 0.6118\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9340 - accuracy: 0.6118\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9267 - accuracy: 0.6245\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9378 - accuracy: 0.5992\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.9237 - accuracy: 0.6245\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9309 - accuracy: 0.6160\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 0.9247 - accuracy: 0.6203\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9206 - accuracy: 0.6245\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9295 - accuracy: 0.6160\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9206 - accuracy: 0.6160\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9255 - accuracy: 0.6118\n",
      "Epoch 95/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9193 - accuracy: 0.6203\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.9192 - accuracy: 0.6160\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 0s 287us/step - loss: 0.9233 - accuracy: 0.6118\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.9203 - accuracy: 0.6118\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9433 - accuracy: 0.6076\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.9423 - accuracy: 0.6118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c489de8a48>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model to the training data\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Improving Results - A Binary Classification Problem\n",
    "\n",
    "Although we achieved promising results, we still have a fairly large error. This could be because it is very difficult to distinguish between the different severity levels of heart disease (classes 1 - 4). Let's simplify the problem by converting the data to a binary classification problem - heart disease or no heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# convert into binary classification problem - heart disease or no heart disease\n",
    "Y_train_binary = y_train.copy()\n",
    "Y_test_binary = y_test.copy()\n",
    "\n",
    "Y_train_binary[Y_train_binary > 0] = 1\n",
    "Y_test_binary[Y_test_binary > 0] = 1\n",
    "\n",
    "print (Y_train_binary[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 112       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define a new keras model for binary classification\n",
    "def create_binary_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=13, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "binary_model = create_binary_model()\n",
    "\n",
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "237/237 [==============================] - 1s 3ms/step - loss: 0.7204 - accuracy: 0.5612\n",
      "Epoch 2/100\n",
      "237/237 [==============================] - 0s 354us/step - loss: 0.6801 - accuracy: 0.5781\n",
      "Epoch 3/100\n",
      "237/237 [==============================] - 0s 388us/step - loss: 0.6782 - accuracy: 0.6118\n",
      "Epoch 4/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.6739 - accuracy: 0.6371\n",
      "Epoch 5/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.6405 - accuracy: 0.6287\n",
      "Epoch 6/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.6310 - accuracy: 0.6456\n",
      "Epoch 7/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.6023 - accuracy: 0.7595\n",
      "Epoch 8/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.5834 - accuracy: 0.7553\n",
      "Epoch 9/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.5740 - accuracy: 0.7131\n",
      "Epoch 10/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.5524 - accuracy: 0.7257\n",
      "Epoch 11/100\n",
      "237/237 [==============================] - 0s 236us/step - loss: 0.5516 - accuracy: 0.7257\n",
      "Epoch 12/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.5221 - accuracy: 0.7511\n",
      "Epoch 13/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.5140 - accuracy: 0.7553\n",
      "Epoch 14/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.5150 - accuracy: 0.7806\n",
      "Epoch 15/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.5034 - accuracy: 0.7848\n",
      "Epoch 16/100\n",
      "237/237 [==============================] - 0s 337us/step - loss: 0.4994 - accuracy: 0.7637\n",
      "Epoch 17/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.4903 - accuracy: 0.7595\n",
      "Epoch 18/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4827 - accuracy: 0.7384\n",
      "Epoch 19/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.4748 - accuracy: 0.7595\n",
      "Epoch 20/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.4791 - accuracy: 0.7764\n",
      "Epoch 21/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.4681 - accuracy: 0.7975\n",
      "Epoch 22/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4652 - accuracy: 0.7637\n",
      "Epoch 23/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4503 - accuracy: 0.7890\n",
      "Epoch 24/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.4328 - accuracy: 0.7848\n",
      "Epoch 25/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4461 - accuracy: 0.7932\n",
      "Epoch 26/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.4503 - accuracy: 0.7806\n",
      "Epoch 27/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.4312 - accuracy: 0.8017\n",
      "Epoch 28/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4383 - accuracy: 0.7848\n",
      "Epoch 29/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.4235 - accuracy: 0.8186\n",
      "Epoch 30/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.4131 - accuracy: 0.8143\n",
      "Epoch 31/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4177 - accuracy: 0.7932\n",
      "Epoch 32/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.4180 - accuracy: 0.8101\n",
      "Epoch 33/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.4242 - accuracy: 0.8186\n",
      "Epoch 34/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.4266 - accuracy: 0.8017\n",
      "Epoch 35/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.3976 - accuracy: 0.8270\n",
      "Epoch 36/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4118 - accuracy: 0.8312\n",
      "Epoch 37/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3977 - accuracy: 0.8312\n",
      "Epoch 38/100\n",
      "237/237 [==============================] - 0s 321us/step - loss: 0.4095 - accuracy: 0.8186\n",
      "Epoch 39/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3903 - accuracy: 0.8312\n",
      "Epoch 40/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.4156 - accuracy: 0.8059\n",
      "Epoch 41/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3944 - accuracy: 0.8439\n",
      "Epoch 42/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.4036 - accuracy: 0.8312\n",
      "Epoch 43/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.3966 - accuracy: 0.8270\n",
      "Epoch 44/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3934 - accuracy: 0.8439\n",
      "Epoch 45/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3929 - accuracy: 0.8143\n",
      "Epoch 46/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.4034 - accuracy: 0.8397\n",
      "Epoch 47/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4102 - accuracy: 0.8101\n",
      "Epoch 48/100\n",
      "237/237 [==============================] - 0s 152us/step - loss: 0.4004 - accuracy: 0.8312\n",
      "Epoch 49/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.3813 - accuracy: 0.8270\n",
      "Epoch 50/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.3821 - accuracy: 0.8523\n",
      "Epoch 51/100\n",
      "237/237 [==============================] - 0s 236us/step - loss: 0.4201 - accuracy: 0.8143\n",
      "Epoch 52/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3888 - accuracy: 0.8397\n",
      "Epoch 53/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3729 - accuracy: 0.8565\n",
      "Epoch 54/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3802 - accuracy: 0.8354\n",
      "Epoch 55/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.3775 - accuracy: 0.8650\n",
      "Epoch 56/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3812 - accuracy: 0.8523\n",
      "Epoch 57/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3903 - accuracy: 0.8312\n",
      "Epoch 58/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3688 - accuracy: 0.8608\n",
      "Epoch 59/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.3839 - accuracy: 0.8439\n",
      "Epoch 60/100\n",
      "237/237 [==============================] - 0s 354us/step - loss: 0.3804 - accuracy: 0.8228\n",
      "Epoch 61/100\n",
      "237/237 [==============================] - 0s 253us/step - loss: 0.3858 - accuracy: 0.8354\n",
      "Epoch 62/100\n",
      "237/237 [==============================] - 0s 236us/step - loss: 0.3680 - accuracy: 0.8439\n",
      "Epoch 63/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3675 - accuracy: 0.8481\n",
      "Epoch 64/100\n",
      "237/237 [==============================] - 0s 169us/step - loss: 0.3742 - accuracy: 0.8439\n",
      "Epoch 65/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3875 - accuracy: 0.8354\n",
      "Epoch 66/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.3701 - accuracy: 0.8439\n",
      "Epoch 67/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.3670 - accuracy: 0.8439\n",
      "Epoch 68/100\n",
      "237/237 [==============================] - 0s 253us/step - loss: 0.3680 - accuracy: 0.8523\n",
      "Epoch 69/100\n",
      "237/237 [==============================] - ETA: 0s - loss: 0.2902 - accuracy: 0.80 - 0s 236us/step - loss: 0.3826 - accuracy: 0.8354\n",
      "Epoch 70/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.3654 - accuracy: 0.8523\n",
      "Epoch 71/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.3763 - accuracy: 0.8481\n",
      "Epoch 72/100\n",
      "237/237 [==============================] - 0s 287us/step - loss: 0.3822 - accuracy: 0.8439\n",
      "Epoch 73/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.3658 - accuracy: 0.8270\n",
      "Epoch 74/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.4259 - accuracy: 0.8481\n",
      "Epoch 75/100\n",
      "237/237 [==============================] - 0s 253us/step - loss: 0.3776 - accuracy: 0.8354\n",
      "Epoch 76/100\n",
      "237/237 [==============================] - 0s 236us/step - loss: 0.3615 - accuracy: 0.8439\n",
      "Epoch 77/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.4168 - accuracy: 0.8270\n",
      "Epoch 78/100\n",
      "237/237 [==============================] - 0s 354us/step - loss: 0.3767 - accuracy: 0.8565\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 0s 321us/step - loss: 0.3584 - accuracy: 0.8692\n",
      "Epoch 80/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.3630 - accuracy: 0.8439\n",
      "Epoch 81/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3670 - accuracy: 0.8439\n",
      "Epoch 82/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3623 - accuracy: 0.8439\n",
      "Epoch 83/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3584 - accuracy: 0.8608\n",
      "Epoch 84/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3776 - accuracy: 0.8312\n",
      "Epoch 85/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3639 - accuracy: 0.8608\n",
      "Epoch 86/100\n",
      "237/237 [==============================] - 0s 193us/step - loss: 0.3618 - accuracy: 0.8397\n",
      "Epoch 87/100\n",
      "237/237 [==============================] - 0s 194us/step - loss: 0.3549 - accuracy: 0.8692\n",
      "Epoch 88/100\n",
      "237/237 [==============================] - 0s 177us/step - loss: 0.3727 - accuracy: 0.8354\n",
      "Epoch 89/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3430 - accuracy: 0.8608\n",
      "Epoch 90/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3659 - accuracy: 0.8608\n",
      "Epoch 91/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3821 - accuracy: 0.8439\n",
      "Epoch 92/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.3659 - accuracy: 0.8397\n",
      "Epoch 93/100\n",
      "237/237 [==============================] - 0s 219us/step - loss: 0.3703 - accuracy: 0.8439\n",
      "Epoch 94/100\n",
      "237/237 [==============================] - 0s 203us/step - loss: 0.3708 - accuracy: 0.8523\n",
      "Epoch 95/100\n",
      "237/237 [==============================] - 0s 202us/step - loss: 0.3557 - accuracy: 0.8650\n",
      "Epoch 96/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3566 - accuracy: 0.8608\n",
      "Epoch 97/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.4049 - accuracy: 0.8228\n",
      "Epoch 98/100\n",
      "237/237 [==============================] - 0s 186us/step - loss: 0.3702 - accuracy: 0.8650\n",
      "Epoch 99/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.3671 - accuracy: 0.8565\n",
      "Epoch 100/100\n",
      "237/237 [==============================] - 0s 270us/step - loss: 0.3684 - accuracy: 0.8565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c48b6c1248>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the binary model on the training data\n",
    "binary_model.fit(X_train, Y_train_binary, epochs=100, batch_size=10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Results and Metrics\n",
    "\n",
    "The accuracy results we have been seeing are for the training data, but what about the testing dataset? If our model's cannot generalize to data that wasn't used to train them, they won't provide any utility. \n",
    "\n",
    "Let's test the performance of both our categorical model and binary model.  To do this, we will make predictions on the training dataset and calculate performance metrics using Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Categorical Model\n",
      "0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        36\n",
      "           1       0.33      0.09      0.14        11\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.35      1.00      0.52         6\n",
      "           4       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.67        60\n",
      "   macro avg       0.30      0.40      0.31        60\n",
      "weighted avg       0.59      0.67      0.60        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# generate classification report using predictions for categorical model\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "categorical_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "print('Results for Categorical Model')\n",
    "print(accuracy_score(y_test, categorical_pred))\n",
    "print(classification_report(y_test, categorical_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Binary Model\n",
      "0.7833333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.75      0.81        36\n",
      "           1       0.69      0.83      0.75        24\n",
      "\n",
      "    accuracy                           0.78        60\n",
      "   macro avg       0.78      0.79      0.78        60\n",
      "weighted avg       0.80      0.78      0.79        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate classification report using predictions for binary model \n",
    "binary_pred = np.round(binary_model.predict(X_test)).astype(int)\n",
    "\n",
    "print('Results for Binary Model')\n",
    "print(accuracy_score(Y_test_binary, binary_pred))\n",
    "print(classification_report(Y_test_binary, binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
